{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c804435d",
   "metadata": {},
   "source": [
    "# HHA550_Diabetes Prediction Dataset\n",
    "\n",
    "## Healtcare-dataset-stroke-data\n",
    "\n",
    "#### (Check Modules folders for csv and ipynb for each class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdf8f594",
   "metadata": {},
   "source": [
    "# DATA\n",
    "## Diabetes Prediction Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96559f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_used = [['readmitted', 'race', 'gender', 'age', 'admission_type_id', 'time_in_hospital', 'A1Cresult', 'diabetesMed', 'number_diagnoses']]\n",
    "# ['race', 'gender', 'age', 'admission_type_id', 'time_in_hospital', 'num_lab_procedures', 'A1Cresult', 'diabetesMed']\n",
    "# ['age', 'A1Cresult', 'diabetesMed', 'time_in_hospital', 'number_diagnoses']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d81386ba",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "According to this [article](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-021-01423-y#Sec12), they have explored machine learning models while looking at variables such as race, sex, age, admission type, admission location, length of stay, and drug. We wanted to approach it similarily with the addition of other variables that could lead to readmission such as A1C results, number of diagnoses, and if they are on diabetes medication which are included in the dataset.\n",
    "\n",
    "We wanted to use weight, as it is a common factor for diabetes, however, in this dataset, there are many NULL or N/A values in weight. Therefore, we decided to keep it out of the machine learning model.\n",
    "\n",
    "#### Simplified Data Dictionary:\n",
    "\n",
    "readmitted\n",
    "```yaml\n",
    "{\n",
    "    0: 'NO',\n",
    "    1: '<30',\n",
    "    0: '>30'\n",
    "}\n",
    "```\n",
    "\n",
    "race\n",
    "```yaml\n",
    "{\n",
    "    1: 'AfricanAmerican',\n",
    "    2: 'Asian',\n",
    "    3: 'Caucasian',\n",
    "    4: 'Hispanic',\n",
    "    999: 'Other',\n",
    "    999: '?'\n",
    "}\n",
    "```\n",
    "\n",
    "gender\n",
    "```yaml\n",
    "{\n",
    "    0: 'Female',\n",
    "    1: 'Male',\n",
    "    999: 'Unknown/Invalid'\n",
    "}\n",
    "```\n",
    "\n",
    "age\n",
    "```yaml\n",
    "{\n",
    "    0: '[0-10)',\n",
    "    1: '[10-20)',\n",
    "    2: '[20-30)',\n",
    "    3: '[30-40)',\n",
    "    4: '[40-50)',\n",
    "    5: '[50-60)',\n",
    "    6: '[60-70)',\n",
    "    7: '[70-80)',\n",
    "    8: '[80-90)',\n",
    "    9: '[90-100)'\n",
    "}\n",
    "```\n",
    "\n",
    "admission_type_id:\n",
    "```yaml\n",
    "{\n",
    "    1: 'Emergency',\n",
    "    2: 'Urgent',\n",
    "    3: 'Elective',\n",
    "    4: 'Newborn',\n",
    "    5: 'Not Available',\n",
    "    6: 'NULL',\n",
    "    7: 'Trauma Center',\n",
    "    8: 'Not Mapped'\n",
    "}\n",
    "```\n",
    "\n",
    "A1Cresult\n",
    "```yaml\n",
    "{\n",
    "    0: 'None',\n",
    "    1: 'Norm',\n",
    "    2: '>7',\n",
    "    3: '>8'\n",
    "}\n",
    "```\n",
    "\n",
    "diabetesMed\n",
    "```yaml\n",
    "{\n",
    "    0: 'No'\n",
    "    1: 'Yes'\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ac477eb",
   "metadata": {},
   "source": [
    "# .CSV Data\n",
    "### cleaned_diabetic_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d98fc5",
   "metadata": {},
   "source": [
    "# IMPORTING Everthing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a10f0b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commands to install some of the libraries in-case if they are not installed\n",
    "# Any other library that needs to be installed just use: !pip install <library name>\n",
    "# !pip install seaborn\n",
    "# !pip install missingno\n",
    "# !pip install xgboost\n",
    "# !pip install catboost\n",
    "# !pip install regex\n",
    "# !pip install sklearn\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install imblearn\n",
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e845f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np   # linear algebra\n",
    "import matplotlib.pyplot as plt  #graphs and plots\n",
    "import seaborn as sns   #data visualizations \n",
    "import csv # Some extra functionalities for csv  files - reading it as a dictionary\n",
    "from lightgbm import LGBMClassifier #sklearn is for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction \n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate   #break up dataset into train and test sets\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "# importing python library for working with missing data\n",
    "import missingno as msno\n",
    "# To install missingno use: !pip install missingno\n",
    "import re    # This library is used to perform regex pattern matching\n",
    "\n",
    "# import various functions from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, classification_report, make_scorer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910c0044",
   "metadata": {},
   "source": [
    "Import additional items as needed...\n",
    "We may not use them all in this course..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee3d031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score, RepeatedStratifiedKFold,StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer,SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score,\\\n",
    "                            precision_score, recall_score, roc_auc_score,\\\n",
    "                            ConfusionMatrixDisplay, classification_report, RocCurveDisplay, f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import plotly \n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "from plotly.offline import iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9136179d",
   "metadata": {},
   "source": [
    "* If from imblearn.oversampling import SMOTE does not load use\n",
    "    `conda install -c conda-forge imbalanced-learn`\n",
    "* Then rerun\n",
    "    `from imblearn.over_sampling import SMOTE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1b5bfa",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe20041",
   "metadata": {},
   "source": [
    "## Start with Loading the CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def56f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Windows/Linux use:\n",
    "dm = pd.read_csv('C:/Users/ttsegyal/Documents/GitHub/HHA550_Analysis/data/cleaned_diabetic_data_final_new.csv')\n",
    "\n",
    "# for MacOS use:\n",
    "# dm - pd.read_csv('/Users/lozo/Developer/AHI_Github/HHA550_Analysis/data/cleaned_diabetic_data_final.csv')\n",
    "\n",
    "# please do not forget to change users when pull to personal machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3afce7",
   "metadata": {},
   "source": [
    "# Breaking the data up into Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23150ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df, test_df = np.split(dm.sample(frac=1, random_state=42), \n",
    "                                        [int(.7*len(dm)), int(0.85*len(dm))])\n",
    "train_df = train_df.reset_index(drop = True)\n",
    "valid_df = valid_df.reset_index(drop = True)\n",
    "test_df = test_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae84eff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    81121\n",
       "1    10249\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "689c1912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    56820\n",
       "1     7138\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "546fc97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12161\n",
       "1     1545\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d1b8408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12140\n",
       "1     1566\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cad6054",
   "metadata": {},
   "source": [
    "# Treating the Imbalance in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ce827",
   "metadata": {},
   "source": [
    "Imbalance in the data means that one of the classes in the data is too less as compared to the others. Typically, it is better to balance the data in some way to give the positives more weight. There are 3 strategies that are typically utilized:\n",
    "\n",
    "* Sub-sample the more dominant class: use a random subset of the negatives\n",
    "* Over-sample the imbalanced class: use the same positive samples multiple times\n",
    "* Create synthetic positive data\n",
    "\n",
    "Usually, you will want to use the latter two methods if you only have a handful of positive cases. Since we have a few thousand positive cases, let's use the sub-sample approach. Here, we will create a balanced training data set that has 50% positive and 50% negative. You can also play with this ratio to see if you can get an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7d35fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prevalence(y_actual):\n",
    "    \n",
    "    '''\n",
    "    This function is to understand the ratio/distribution of the classes that we are going to predict for.\n",
    "    \n",
    "    Params:\n",
    "    1. y_actual: The target feature\n",
    "    \n",
    "    Return:\n",
    "    1. (sum(y_actual)/len(y_actual)): The ratio of the postive class in the comlpete data.\n",
    "    '''\n",
    "    \n",
    "    return (sum(y_actual)/len(y_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a9dfc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train balanced prevalence(n = 14276):0.500\n"
     ]
    }
   ],
   "source": [
    "# split the training data into positive and negative\n",
    "rows_pos = train_df.readmitted == 1\n",
    "df_train_pos = train_df.loc[rows_pos]\n",
    "df_train_neg = train_df.loc[~rows_pos]\n",
    "\n",
    "# merge the balanced data\n",
    "dm_df_balanced = pd.concat([df_train_pos, df_train_neg.sample(n = len(df_train_pos), random_state = 111)],axis = 0)\n",
    "\n",
    "# shuffle the order of training samples \n",
    "dm_df_balanced = dm_df_balanced.sample(n = len(dm_df_balanced), random_state = 42).reset_index(drop = True)\n",
    "\n",
    "print('Train balanced prevalence(n = %d):%.3f'%(len(dm_df_balanced), \\\n",
    "                                                calc_prevalence(dm_df_balanced.readmitted.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "938bbaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7138\n",
       "1    7138\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_df_balanced.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7590ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dm_df_balanced.drop('readmitted',axis=1)\n",
    "\n",
    "y_train = dm_df_balanced['readmitted']\n",
    "\n",
    "X_valid = valid_df.drop('readmitted',axis=1)\n",
    "\n",
    "y_valid = valid_df['readmitted']\n",
    "\n",
    "X_test = test_df.drop('readmitted',axis=1)\n",
    "\n",
    "y_test = test_df['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b5c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_train[['race', 'gender', 'age', 'admission_type_id', 'time_in_hospital', 'num_lab_procedures', 'A1Cresult', 'diabetesMed']] = pd.DataFrame(scaler.fit_transform(X_train[['race', 'gender', 'age', 'admission_type_id', 'time_in_hospital', 'num_lab_procedures', 'A1Cresult', 'diabetesMed']]),columns=['race', 'gender', 'age', 'admission_type_id', 'time_in_hospital', 'num_lab_procedures', 'A1Cresult', 'diabetesMed'])\n",
    "X_valid[['race', 'gender', 'age', 'admission_type_id', 'time_in_hospital', 'num_lab_procedures', 'A1Cresult', 'diabetesMed']] = pd.DataFrame(scaler.transform(X_valid[['race', 'gender', 'age', 'admission_type_id', 'time_in_hospital', 'num_lab_procedures', 'A1Cresult', 'diabetesMed']]),columns=['race', 'gender', 'age', 'admission_type_id', 'time_in_hospital', 'num_lab_procedures', 'A1Cresult', 'diabetesMed'])\n",
    "X_test[['race', 'gender', 'age', 'admission_type_id', 'time_in_hospital', 'num_lab_procedures', 'A1Cresult', 'diabetesMed']] = pd.DataFrame(scaler.transform(X_test[['race', 'gender', 'age', 'admission_type_id', 'time_in_hospital', 'num_lab_procedures', 'A1Cresult', 'diabetesMed']]),columns=['race', 'gender', 'age', 'admission_type_id', 'time_in_hospital', 'num_lab_procedures', 'A1Cresult', 'diabetesMed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e5723",
   "metadata": {},
   "source": [
    "# Creating and Understanding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecf8b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh = 0.5):\n",
    "    \n",
    "    '''\n",
    "    This function calculates all the metrics to asses the machine learning models.\n",
    "    \n",
    "    Params:\n",
    "    1. y_actual: The actual values for the target variable.\n",
    "    2. y_pred: The predicted values for the target variable.\n",
    "    3. thresh: The threshold for the probability to be considered as a positive class. Default value 0.5\n",
    "    \n",
    "    Return:\n",
    "    1. AUC\n",
    "    2. Accuracy\n",
    "    3. Recall\n",
    "    4. Precision\n",
    "    5. Specificity\n",
    "    '''\n",
    "    \n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print('prevalence:%.3f'%calc_prevalence(y_actual))\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba8c8ea",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d02dbec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnr = LinearRegression()\n",
    "lnr.fit(X_train, y_train)\n",
    "\n",
    "y_valid_preds = lnr.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef7f15a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38538915, 0.4350514 , 0.59560325, ..., 0.43512876, 0.42127774,\n",
       "       0.32270968])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c7731",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5086c49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Validation data:\n",
      "AUC:0.617\n",
      "accuracy:0.659\n",
      "recall:0.471\n",
      "precision:0.159\n",
      "specificity:0.683\n",
      "prevalence:0.113\n",
      " \n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(random_state = 42, solver = 'newton-cg', max_iter = 200)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_valid_preds = lr.predict_proba(X_valid)[:,1]\n",
    "\n",
    "print('Metrics for Validation data:')\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,y_valid_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba01c6",
   "metadata": {},
   "source": [
    "## Explaining Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4691cdbb",
   "metadata": {},
   "source": [
    "Lets look at some other models to see if we get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3555e949",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cba627ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:0.509\n",
      "accuracy:0.535\n",
      "recall:0.475\n",
      "precision:0.116\n",
      "specificity:0.469\n",
      "prevalence:0.113\n",
      " \n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 100)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn_preds = knn.predict_proba(X_valid)[:,1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,knn_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2268172",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "167f592a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent\n",
      "Validation:\n",
      "AUC:0.501\n",
      "accuracy:0.113\n",
      "recall:1.000\n",
      "precision:0.113\n",
      "specificity:0.000\n",
      "prevalence:0.113\n",
      " \n"
     ]
    }
   ],
   "source": [
    "sgdc=SGDClassifier(loss = 'log',alpha = 0.1,random_state = 42)\n",
    "sgdc.fit(X_train, y_train)\n",
    "\n",
    "sgd_preds = sgdc.predict_proba(X_valid)[:,1]\n",
    "\n",
    "print('Stochastic Gradient Descent')\n",
    "print('Validation:')\n",
    "sgdc_valid_auc, sgdc_valid_accuracy, sgdc_valid_recall, \\\n",
    "                sgdc_valid_precision, sgdc_valid_specificity = print_report(y_valid,sgd_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e841c95",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c524b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:0.580\n",
      "accuracy:0.546\n",
      "recall:0.584\n",
      "precision:0.139\n",
      "specificity:0.531\n",
      "prevalence:0.113\n",
      " \n"
     ]
    }
   ],
   "source": [
    "dc_clf = DecisionTreeClassifier(random_state=42, max_depth = 10)\n",
    "dc_clf.fit(X_train, y_train)\n",
    "\n",
    "dc_preds_proba = dc_clf.predict_proba(X_valid)[:,1]\n",
    "dc_preds = dc_clf.predict(X_valid)\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,dc_preds_proba, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24a7e5b",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "009ae20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:0.622\n",
      "accuracy:0.631\n",
      "recall:0.532\n",
      "precision:0.159\n",
      "specificity:0.643\n",
      "prevalence:0.113\n",
      " \n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=111, max_depth = 6)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "rf_preds = rf_clf.predict(X_valid)\n",
    "rf_preds_proba = rf_clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,rf_preds_proba, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ea500",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "893e28ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:0.510\n",
      "accuracy:0.878\n",
      "recall:0.011\n",
      "precision:0.102\n",
      "specificity:0.988\n",
      "prevalence:0.113\n",
      " \n"
     ]
    }
   ],
   "source": [
    "lsvc_clf = LinearSVC(random_state=111)\n",
    "lsvc_clf.fit(X_train, y_train)\n",
    "\n",
    "lsvc_preds = lsvc_clf.decision_function(X_valid)\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,lsvc_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d1087",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6e1e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:0.584\n",
      "accuracy:0.575\n",
      "recall:0.550\n",
      "precision:0.142\n",
      "specificity:0.578\n",
      "prevalence:0.113\n",
      " \n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators = 100, criterion='friedman_mse', learning_rate = 1.0, max_depth = 3,\\\n",
    "                                    random_state = 111)\n",
    "\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_preds = gb_clf.predict(X_valid)\n",
    "gb_preds_proba = gb_clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,gb_preds_proba, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe0a53",
   "metadata": {},
   "source": [
    "## XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83f18546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:0.589\n",
      "accuracy:0.577\n",
      "recall:0.553\n",
      "precision:0.143\n",
      "specificity:0.580\n",
      "prevalence:0.113\n",
      " \n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(max_depth=3, learning_rate = 1.0, use_label_encoder = False,\\\n",
    "                            eval_metric = 'logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "xgb_preds = xgb_clf.predict(X_valid)\n",
    "xgb_preds_proba = xgb_clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,xgb_preds_proba, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc6c12",
   "metadata": {},
   "source": [
    "## Catboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbba6d6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6712209\ttotal: 180ms\tremaining: 35.8s\n",
      "1:\tlearn: 0.6679819\ttotal: 187ms\tremaining: 18.5s\n",
      "2:\tlearn: 0.6631642\ttotal: 193ms\tremaining: 12.7s\n",
      "3:\tlearn: 0.6611258\ttotal: 198ms\tremaining: 9.71s\n",
      "4:\tlearn: 0.6595001\ttotal: 205ms\tremaining: 7.99s\n",
      "5:\tlearn: 0.6589517\ttotal: 211ms\tremaining: 6.83s\n",
      "6:\tlearn: 0.6584081\ttotal: 217ms\tremaining: 5.99s\n",
      "7:\tlearn: 0.6578275\ttotal: 224ms\tremaining: 5.37s\n",
      "8:\tlearn: 0.6573286\ttotal: 230ms\tremaining: 4.88s\n",
      "9:\tlearn: 0.6567472\ttotal: 236ms\tremaining: 4.49s\n",
      "10:\tlearn: 0.6559875\ttotal: 242ms\tremaining: 4.16s\n",
      "11:\tlearn: 0.6549511\ttotal: 249ms\tremaining: 3.9s\n",
      "12:\tlearn: 0.6535885\ttotal: 255ms\tremaining: 3.66s\n",
      "13:\tlearn: 0.6522930\ttotal: 261ms\tremaining: 3.46s\n",
      "14:\tlearn: 0.6517712\ttotal: 267ms\tremaining: 3.29s\n",
      "15:\tlearn: 0.6509543\ttotal: 273ms\tremaining: 3.14s\n",
      "16:\tlearn: 0.6499725\ttotal: 278ms\tremaining: 2.99s\n",
      "17:\tlearn: 0.6492583\ttotal: 283ms\tremaining: 2.86s\n",
      "18:\tlearn: 0.6482630\ttotal: 288ms\tremaining: 2.74s\n",
      "19:\tlearn: 0.6474411\ttotal: 293ms\tremaining: 2.64s\n",
      "20:\tlearn: 0.6467815\ttotal: 300ms\tremaining: 2.55s\n",
      "21:\tlearn: 0.6461940\ttotal: 306ms\tremaining: 2.47s\n",
      "22:\tlearn: 0.6455343\ttotal: 312ms\tremaining: 2.4s\n",
      "23:\tlearn: 0.6449359\ttotal: 318ms\tremaining: 2.33s\n",
      "24:\tlearn: 0.6442400\ttotal: 323ms\tremaining: 2.26s\n",
      "25:\tlearn: 0.6437813\ttotal: 329ms\tremaining: 2.2s\n",
      "26:\tlearn: 0.6428220\ttotal: 336ms\tremaining: 2.15s\n",
      "27:\tlearn: 0.6423721\ttotal: 342ms\tremaining: 2.1s\n",
      "28:\tlearn: 0.6421092\ttotal: 348ms\tremaining: 2.05s\n",
      "29:\tlearn: 0.6410581\ttotal: 353ms\tremaining: 2s\n",
      "30:\tlearn: 0.6407156\ttotal: 360ms\tremaining: 1.96s\n",
      "31:\tlearn: 0.6398816\ttotal: 365ms\tremaining: 1.91s\n",
      "32:\tlearn: 0.6394899\ttotal: 370ms\tremaining: 1.87s\n",
      "33:\tlearn: 0.6391474\ttotal: 376ms\tremaining: 1.83s\n",
      "34:\tlearn: 0.6386924\ttotal: 382ms\tremaining: 1.8s\n",
      "35:\tlearn: 0.6382658\ttotal: 387ms\tremaining: 1.76s\n",
      "36:\tlearn: 0.6378085\ttotal: 393ms\tremaining: 1.73s\n",
      "37:\tlearn: 0.6373052\ttotal: 399ms\tremaining: 1.7s\n",
      "38:\tlearn: 0.6366249\ttotal: 405ms\tremaining: 1.67s\n",
      "39:\tlearn: 0.6359945\ttotal: 410ms\tremaining: 1.64s\n",
      "40:\tlearn: 0.6357395\ttotal: 417ms\tremaining: 1.62s\n",
      "41:\tlearn: 0.6353542\ttotal: 423ms\tremaining: 1.59s\n",
      "42:\tlearn: 0.6346200\ttotal: 429ms\tremaining: 1.57s\n",
      "43:\tlearn: 0.6340342\ttotal: 435ms\tremaining: 1.54s\n",
      "44:\tlearn: 0.6336740\ttotal: 440ms\tremaining: 1.52s\n",
      "45:\tlearn: 0.6332474\ttotal: 445ms\tremaining: 1.49s\n",
      "46:\tlearn: 0.6329149\ttotal: 451ms\tremaining: 1.47s\n",
      "47:\tlearn: 0.6323828\ttotal: 456ms\tremaining: 1.45s\n",
      "48:\tlearn: 0.6318426\ttotal: 462ms\tremaining: 1.42s\n",
      "49:\tlearn: 0.6310090\ttotal: 469ms\tremaining: 1.41s\n",
      "50:\tlearn: 0.6303647\ttotal: 474ms\tremaining: 1.38s\n",
      "51:\tlearn: 0.6299737\ttotal: 479ms\tremaining: 1.36s\n",
      "52:\tlearn: 0.6296133\ttotal: 485ms\tremaining: 1.34s\n",
      "53:\tlearn: 0.6292890\ttotal: 491ms\tremaining: 1.33s\n",
      "54:\tlearn: 0.6291891\ttotal: 496ms\tremaining: 1.31s\n",
      "55:\tlearn: 0.6287018\ttotal: 502ms\tremaining: 1.29s\n",
      "56:\tlearn: 0.6281684\ttotal: 508ms\tremaining: 1.27s\n",
      "57:\tlearn: 0.6278520\ttotal: 514ms\tremaining: 1.26s\n",
      "58:\tlearn: 0.6271679\ttotal: 519ms\tremaining: 1.24s\n",
      "59:\tlearn: 0.6266773\ttotal: 524ms\tremaining: 1.22s\n",
      "60:\tlearn: 0.6264902\ttotal: 530ms\tremaining: 1.21s\n",
      "61:\tlearn: 0.6264852\ttotal: 536ms\tremaining: 1.19s\n",
      "62:\tlearn: 0.6262324\ttotal: 541ms\tremaining: 1.18s\n",
      "63:\tlearn: 0.6254586\ttotal: 547ms\tremaining: 1.16s\n",
      "64:\tlearn: 0.6247225\ttotal: 552ms\tremaining: 1.15s\n",
      "65:\tlearn: 0.6242981\ttotal: 558ms\tremaining: 1.13s\n",
      "66:\tlearn: 0.6237536\ttotal: 562ms\tremaining: 1.12s\n",
      "67:\tlearn: 0.6237296\ttotal: 568ms\tremaining: 1.1s\n",
      "68:\tlearn: 0.6232554\ttotal: 573ms\tremaining: 1.09s\n",
      "69:\tlearn: 0.6231096\ttotal: 579ms\tremaining: 1.07s\n",
      "70:\tlearn: 0.6225951\ttotal: 585ms\tremaining: 1.06s\n",
      "71:\tlearn: 0.6223948\ttotal: 591ms\tremaining: 1.05s\n",
      "72:\tlearn: 0.6221109\ttotal: 597ms\tremaining: 1.04s\n",
      "73:\tlearn: 0.6215651\ttotal: 602ms\tremaining: 1.02s\n",
      "74:\tlearn: 0.6212455\ttotal: 607ms\tremaining: 1.01s\n",
      "75:\tlearn: 0.6211435\ttotal: 613ms\tremaining: 1s\n",
      "76:\tlearn: 0.6207775\ttotal: 619ms\tremaining: 990ms\n",
      "77:\tlearn: 0.6203982\ttotal: 626ms\tremaining: 979ms\n",
      "78:\tlearn: 0.6200159\ttotal: 632ms\tremaining: 968ms\n",
      "79:\tlearn: 0.6197448\ttotal: 638ms\tremaining: 957ms\n",
      "80:\tlearn: 0.6193351\ttotal: 643ms\tremaining: 945ms\n",
      "81:\tlearn: 0.6188575\ttotal: 649ms\tremaining: 934ms\n",
      "82:\tlearn: 0.6184133\ttotal: 655ms\tremaining: 923ms\n",
      "83:\tlearn: 0.6178868\ttotal: 661ms\tremaining: 913ms\n",
      "84:\tlearn: 0.6174121\ttotal: 667ms\tremaining: 902ms\n",
      "85:\tlearn: 0.6169925\ttotal: 671ms\tremaining: 890ms\n",
      "86:\tlearn: 0.6166035\ttotal: 677ms\tremaining: 880ms\n",
      "87:\tlearn: 0.6162236\ttotal: 682ms\tremaining: 868ms\n",
      "88:\tlearn: 0.6158720\ttotal: 689ms\tremaining: 859ms\n",
      "89:\tlearn: 0.6153674\ttotal: 694ms\tremaining: 848ms\n",
      "90:\tlearn: 0.6149004\ttotal: 700ms\tremaining: 839ms\n",
      "91:\tlearn: 0.6144515\ttotal: 707ms\tremaining: 830ms\n",
      "92:\tlearn: 0.6140887\ttotal: 714ms\tremaining: 821ms\n",
      "93:\tlearn: 0.6136448\ttotal: 721ms\tremaining: 813ms\n",
      "94:\tlearn: 0.6133024\ttotal: 728ms\tremaining: 804ms\n",
      "95:\tlearn: 0.6128309\ttotal: 734ms\tremaining: 795ms\n",
      "96:\tlearn: 0.6124370\ttotal: 741ms\tremaining: 786ms\n",
      "97:\tlearn: 0.6121401\ttotal: 747ms\tremaining: 777ms\n",
      "98:\tlearn: 0.6118557\ttotal: 753ms\tremaining: 768ms\n",
      "99:\tlearn: 0.6116593\ttotal: 759ms\tremaining: 759ms\n",
      "100:\tlearn: 0.6111796\ttotal: 764ms\tremaining: 749ms\n",
      "101:\tlearn: 0.6110084\ttotal: 771ms\tremaining: 740ms\n",
      "102:\tlearn: 0.6103866\ttotal: 777ms\tremaining: 731ms\n",
      "103:\tlearn: 0.6099245\ttotal: 782ms\tremaining: 722ms\n",
      "104:\tlearn: 0.6095584\ttotal: 788ms\tremaining: 713ms\n",
      "105:\tlearn: 0.6092988\ttotal: 793ms\tremaining: 703ms\n",
      "106:\tlearn: 0.6092700\ttotal: 799ms\tremaining: 695ms\n",
      "107:\tlearn: 0.6087837\ttotal: 805ms\tremaining: 686ms\n",
      "108:\tlearn: 0.6085071\ttotal: 810ms\tremaining: 676ms\n",
      "109:\tlearn: 0.6079935\ttotal: 816ms\tremaining: 668ms\n",
      "110:\tlearn: 0.6074932\ttotal: 822ms\tremaining: 659ms\n",
      "111:\tlearn: 0.6073571\ttotal: 827ms\tremaining: 650ms\n",
      "112:\tlearn: 0.6072817\ttotal: 833ms\tremaining: 642ms\n",
      "113:\tlearn: 0.6068282\ttotal: 839ms\tremaining: 633ms\n",
      "114:\tlearn: 0.6065364\ttotal: 845ms\tremaining: 625ms\n",
      "115:\tlearn: 0.6061882\ttotal: 851ms\tremaining: 617ms\n",
      "116:\tlearn: 0.6056900\ttotal: 857ms\tremaining: 608ms\n",
      "117:\tlearn: 0.6053153\ttotal: 864ms\tremaining: 600ms\n",
      "118:\tlearn: 0.6050886\ttotal: 870ms\tremaining: 592ms\n",
      "119:\tlearn: 0.6045791\ttotal: 875ms\tremaining: 583ms\n",
      "120:\tlearn: 0.6041156\ttotal: 881ms\tremaining: 575ms\n",
      "121:\tlearn: 0.6036506\ttotal: 886ms\tremaining: 567ms\n",
      "122:\tlearn: 0.6035964\ttotal: 892ms\tremaining: 559ms\n",
      "123:\tlearn: 0.6032386\ttotal: 898ms\tremaining: 550ms\n",
      "124:\tlearn: 0.6029045\ttotal: 904ms\tremaining: 542ms\n",
      "125:\tlearn: 0.6027087\ttotal: 910ms\tremaining: 534ms\n",
      "126:\tlearn: 0.6021144\ttotal: 916ms\tremaining: 527ms\n",
      "127:\tlearn: 0.6020000\ttotal: 922ms\tremaining: 519ms\n",
      "128:\tlearn: 0.6016338\ttotal: 929ms\tremaining: 511ms\n",
      "129:\tlearn: 0.6012519\ttotal: 935ms\tremaining: 503ms\n",
      "130:\tlearn: 0.6009946\ttotal: 941ms\tremaining: 496ms\n",
      "131:\tlearn: 0.6006949\ttotal: 946ms\tremaining: 487ms\n",
      "132:\tlearn: 0.6003743\ttotal: 952ms\tremaining: 480ms\n",
      "133:\tlearn: 0.5999315\ttotal: 958ms\tremaining: 472ms\n",
      "134:\tlearn: 0.5995882\ttotal: 963ms\tremaining: 464ms\n",
      "135:\tlearn: 0.5992904\ttotal: 970ms\tremaining: 456ms\n",
      "136:\tlearn: 0.5988316\ttotal: 975ms\tremaining: 448ms\n",
      "137:\tlearn: 0.5985273\ttotal: 981ms\tremaining: 441ms\n",
      "138:\tlearn: 0.5982580\ttotal: 987ms\tremaining: 433ms\n",
      "139:\tlearn: 0.5979218\ttotal: 993ms\tremaining: 426ms\n",
      "140:\tlearn: 0.5974939\ttotal: 998ms\tremaining: 418ms\n",
      "141:\tlearn: 0.5968968\ttotal: 1s\tremaining: 410ms\n",
      "142:\tlearn: 0.5966262\ttotal: 1.01s\tremaining: 402ms\n",
      "143:\tlearn: 0.5965662\ttotal: 1.01s\tremaining: 395ms\n",
      "144:\tlearn: 0.5965466\ttotal: 1.02s\tremaining: 387ms\n",
      "145:\tlearn: 0.5962796\ttotal: 1.03s\tremaining: 380ms\n",
      "146:\tlearn: 0.5959327\ttotal: 1.03s\tremaining: 372ms\n",
      "147:\tlearn: 0.5956827\ttotal: 1.04s\tremaining: 365ms\n",
      "148:\tlearn: 0.5953407\ttotal: 1.04s\tremaining: 357ms\n",
      "149:\tlearn: 0.5950653\ttotal: 1.05s\tremaining: 350ms\n",
      "150:\tlearn: 0.5948175\ttotal: 1.06s\tremaining: 343ms\n",
      "151:\tlearn: 0.5947082\ttotal: 1.06s\tremaining: 335ms\n",
      "152:\tlearn: 0.5945213\ttotal: 1.07s\tremaining: 328ms\n",
      "153:\tlearn: 0.5939971\ttotal: 1.07s\tremaining: 321ms\n",
      "154:\tlearn: 0.5937382\ttotal: 1.08s\tremaining: 313ms\n",
      "155:\tlearn: 0.5934251\ttotal: 1.08s\tremaining: 306ms\n",
      "156:\tlearn: 0.5929618\ttotal: 1.09s\tremaining: 299ms\n",
      "157:\tlearn: 0.5925279\ttotal: 1.1s\tremaining: 292ms\n",
      "158:\tlearn: 0.5922685\ttotal: 1.1s\tremaining: 284ms\n",
      "159:\tlearn: 0.5918227\ttotal: 1.11s\tremaining: 277ms\n",
      "160:\tlearn: 0.5916262\ttotal: 1.11s\tremaining: 270ms\n",
      "161:\tlearn: 0.5912033\ttotal: 1.12s\tremaining: 262ms\n",
      "162:\tlearn: 0.5909211\ttotal: 1.12s\tremaining: 255ms\n",
      "163:\tlearn: 0.5905608\ttotal: 1.13s\tremaining: 248ms\n",
      "164:\tlearn: 0.5900347\ttotal: 1.14s\tremaining: 241ms\n",
      "165:\tlearn: 0.5896885\ttotal: 1.14s\tremaining: 234ms\n",
      "166:\tlearn: 0.5891944\ttotal: 1.15s\tremaining: 226ms\n",
      "167:\tlearn: 0.5889371\ttotal: 1.15s\tremaining: 219ms\n",
      "168:\tlearn: 0.5888203\ttotal: 1.16s\tremaining: 212ms\n",
      "169:\tlearn: 0.5884448\ttotal: 1.16s\tremaining: 205ms\n",
      "170:\tlearn: 0.5882641\ttotal: 1.17s\tremaining: 198ms\n",
      "171:\tlearn: 0.5878200\ttotal: 1.17s\tremaining: 191ms\n",
      "172:\tlearn: 0.5873724\ttotal: 1.18s\tremaining: 184ms\n",
      "173:\tlearn: 0.5868898\ttotal: 1.19s\tremaining: 177ms\n",
      "174:\tlearn: 0.5866233\ttotal: 1.19s\tremaining: 170ms\n",
      "175:\tlearn: 0.5862661\ttotal: 1.2s\tremaining: 163ms\n",
      "176:\tlearn: 0.5859038\ttotal: 1.2s\tremaining: 156ms\n",
      "177:\tlearn: 0.5855283\ttotal: 1.21s\tremaining: 149ms\n",
      "178:\tlearn: 0.5851836\ttotal: 1.21s\tremaining: 142ms\n",
      "179:\tlearn: 0.5848343\ttotal: 1.22s\tremaining: 135ms\n",
      "180:\tlearn: 0.5843625\ttotal: 1.22s\tremaining: 129ms\n",
      "181:\tlearn: 0.5841481\ttotal: 1.23s\tremaining: 122ms\n",
      "182:\tlearn: 0.5839123\ttotal: 1.24s\tremaining: 115ms\n",
      "183:\tlearn: 0.5833480\ttotal: 1.24s\tremaining: 108ms\n",
      "184:\tlearn: 0.5829599\ttotal: 1.25s\tremaining: 101ms\n",
      "185:\tlearn: 0.5824768\ttotal: 1.26s\tremaining: 94.5ms\n",
      "186:\tlearn: 0.5821516\ttotal: 1.26s\tremaining: 87.7ms\n",
      "187:\tlearn: 0.5818958\ttotal: 1.27s\tremaining: 80.9ms\n",
      "188:\tlearn: 0.5815963\ttotal: 1.27s\tremaining: 74.1ms\n",
      "189:\tlearn: 0.5810837\ttotal: 1.28s\tremaining: 67.4ms\n",
      "190:\tlearn: 0.5807288\ttotal: 1.28s\tremaining: 60.6ms\n",
      "191:\tlearn: 0.5805550\ttotal: 1.29s\tremaining: 53.8ms\n",
      "192:\tlearn: 0.5802011\ttotal: 1.3s\tremaining: 47.1ms\n",
      "193:\tlearn: 0.5798997\ttotal: 1.3s\tremaining: 40.3ms\n",
      "194:\tlearn: 0.5796397\ttotal: 1.31s\tremaining: 33.6ms\n",
      "195:\tlearn: 0.5793508\ttotal: 1.31s\tremaining: 26.8ms\n",
      "196:\tlearn: 0.5791916\ttotal: 1.32s\tremaining: 20.1ms\n",
      "197:\tlearn: 0.5787402\ttotal: 1.33s\tremaining: 13.4ms\n",
      "198:\tlearn: 0.5784030\ttotal: 1.33s\tremaining: 6.7ms\n",
      "199:\tlearn: 0.5781890\ttotal: 1.34s\tremaining: 0us\n",
      "AUC:0.587\n",
      "accuracy:0.578\n",
      "recall:0.536\n",
      "precision:0.141\n",
      "specificity:0.584\n",
      "prevalence:0.113\n",
      " \n"
     ]
    }
   ],
   "source": [
    "catb=CatBoostClassifier(iterations=200, depth=3, learning_rate=1.0, random_state = 111)\n",
    "catb.fit(X_train, y_train)\n",
    "catb_preds = catb.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,catb_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6128b0e",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb5ce3",
   "metadata": {},
   "source": [
    "* From the above models we will choose two models for demonstration i.e. Random Forest, Decision Trees for hyper-parameter tuning.\n",
    "* Generally you can pick up the top three models based on the 'AUC', 'Recall' or 'F1 score' score and tune them.\n",
    "\n",
    "There are many techniques for hyper-parameter tuning:\n",
    "\n",
    "* Random Search\n",
    "* Grid Search\n",
    "* Halving Grid Search(added recently in sklearn)\n",
    "\n",
    "Special Note:\n",
    "* It will take significant time to run Hyper Parameter Tuning \n",
    "* Timing will depend on available resources of server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "367dc1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_scoring = make_scorer(recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75172b",
   "metadata": {},
   "source": [
    "## Decision Tree - Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4a7af70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5982965333767636"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_grid = {'max_features':['auto','sqrt'], # maximum number of features to use at each split\n",
    "           'max_depth':range(1,11,1), # maximum depth of the tree\n",
    "           'min_samples_split':range(2,10,2), # minimum number of samples to split a node\n",
    "           'criterion':['gini','entropy']} # criterion for evaluating a split\n",
    "\n",
    "dc_random = RandomizedSearchCV(estimator = dc_clf, param_distributions = dc_grid, \n",
    "                               n_iter = 20, cv = 2, scoring=recall_scoring,\n",
    "                               verbose = 1, random_state = 111)\n",
    "\n",
    "dc_random.fit(X_train, y_train)\n",
    "\n",
    "dc_random.best_params_\n",
    "\n",
    "dc_hp_preds = dc_random.best_estimator_.predict(X_valid)\n",
    "dc_hp_preds_proba = dc_random.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "roc_auc_score(y_valid, dc_hp_preds_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9af302e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5637540453074433"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_valid, dc_hp_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588787d3",
   "metadata": {},
   "source": [
    "## Random Forest - Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7f41f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6279277833617946"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid = {'n_estimators':range(200,1000,200), # number of trees\n",
    "           'max_features':['auto','sqrt'], # maximum number of features to use at each split\n",
    "           'max_depth':range(1,11,1), # maximum depth of the tree\n",
    "           'min_samples_split':range(2,10,2), # minimum number of samples to split a node\n",
    "           'criterion':['gini','entropy']} # criterion for evaluating a split\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf_clf, param_distributions = rf_grid, \n",
    "                               n_iter = 20, cv = 2, scoring=recall_scoring,\n",
    "                               verbose = 1, random_state = 111)\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_random.best_params_\n",
    "\n",
    "rf_hp_preds = rf_random.best_estimator_.predict(X_valid)\n",
    "rf_hp_preds_proba = rf_random.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "roc_auc_score(y_valid, rf_hp_preds_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e9765ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5579288025889968"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_valid, rf_hp_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d26f2a0",
   "metadata": {},
   "source": [
    "## XGBoost - Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bd2859b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 720 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6068261078640431"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid = params = {\n",
    "        'min_child_weight': [1, 5, 8, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 0.9, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        } # criterion for evaluating a split\n",
    "\n",
    "xgb_random = GridSearchCV(estimator = xgb_clf, param_grid = xgb_grid, \n",
    "                                cv = 2, scoring = recall_scoring,\n",
    "                                verbose = 1)\n",
    "\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "xgb_random.best_params_\n",
    "\n",
    "xgb_hp_preds = xgb_random.best_estimator_.predict(X_valid)\n",
    "xgb_hp_preds_proba = xgb_random.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "roc_auc_score(y_valid, xgb_hp_preds_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f6d46c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5540453074433657"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_valid, xgb_hp_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20acf821",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We found that the RF (Random Forest) algorithm produced the best results with an AUC of 65.0% and a recall of 61.9%. \n",
    "\n",
    "These were the results we were expecting with the data given to us. However, we believe that with additional medical history, the results of the machine learning models would have improved. If we had more information on each patient's weight, their family history or their BMI, the results of the models could have improved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe6db6d2",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "Shang, Y., Jiang, K., Wang, L. et al. The 30-days hospital readmission risk in diabetic patients: predictive modeling with machine learning classifiers. BMC Med Inform Decis Mak 21 (Suppl 2), 57 (2021). https://doi.org/10.1186/s12911-021-01423-y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e069c0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "43dbda674042127dbd4f9343b1c057265239bc978a327eaddcf7b25ec0d1ff26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
